---
title: "Analiza danych z mediów społecznościowych"
author: Agnieszka Karlińska
output: html_notebook
---

Ładowanie potrzebnych pakietów:

```{r}
library(dplyr)
library(tidytext)
library(ggplot2)
library(readxl)
library(readr)
library(wordcloud)
library(quanteda)
```

# Etapy pracy z danymi

## Pozyskiwanie tweetów (Twitter API)

```{r}
install.packages("rtweet")
library(rtweet)

api_key <- "xxxx"
api_secret_key <- "xxxx"
```

```{r}
token <- create_token(
  app = "xxxx",
  consumer_key = api_key,
  consumer_secret = api_secret_key)
```

```{r}
strajk <- search_tweets("#StrajkKobiet", 
                 n = 10000, 
                 include_rts = TRUE, 
                 lang = "pl")
```

## Wczytanie zbioru danych

```{r}
strajk <- read_xlsx("strajk.xlsx")
```

```{r}
View(strajk)
```

```{r}
strajk_tweets <- strajk %>%
  select(user_id, created_at, is_retweet, retweet_count, text)

head(strajk_tweets)
```

## Czyszczenie danych

```{r}
strajk_tweets_clean <- strajk_tweets %>%
        mutate(created_at = as.POSIXct(created_at, format = "%a %b %d %H:%M:%S +0000 %Y"), 
               tweet_text = gsub("\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)", 
                                 "", text),
               tweet_text = gsub("[[:punct:]]", 
                                 " " , tweet_text),
               tweet_text2 = gsub("\\b\\d+\\b", " ", tweet_text),
               tweet_text2 = gsub("\\s+"," ",tweet_text2))
         
head(strajk_tweets_clean)
```

## Tokenizacja, lematyzacja, stoplista

Tokenizacja (wersja podstawowa):

```{r}
strajk_token <- strajk_tweets_clean %>%
  unnest_tokens(word, tweet_text2)
```

```{r}
count(strajk_token, word, sort = T)
```

Zbiór po lematyzacji i usunięciu emotikonów (Python):

```{r}
strajk_lem <- read_xlsx("strajk_lemat.xlsx")
View(strajk_lem)
```

Tokenizacja raz jeszcze:

```{r}
strajk_tok <- strajk_lem %>%
  unnest_tokens(word, lemat) 

count(strajk_tok, word, sort = T)
```

Usuwanie słów ze stoplisty:

```{r}
stoplista <- read_xlsx("stoplista.xlsx")
strajk_clean <- strajk_tok %>%
  anti_join(stoplista)

count(strajk_clean, word, sort = T)
```

```{r}
stoplista2 <- tibble(word = c("strajkkobiet", "piekłokobiet", "kobieta"))

strajk_clean2 <- strajk_clean %>%
  anti_join(stoplista2)

count(strajk_clean2, word, sort = T)
```
Usuwanie błędów lematyzacji:

```{r}
strajk_clean2$word <- gsub("niczego","nic", strajk_clean2$word)
strajk_clean2$word <- gsub("bogu","bóg", strajk_clean2$word)
strajk_clean2$word <- gsub("opublikowaniu","opublikowanie", strajk_clean2$word)
strajk_clean2$word <- gsub("naszym","nasz", strajk_clean2$word)
strajk_clean2$word <- gsub("mojej","mój", strajk_clean2$word)
count(strajk_clean2, word, sort = T)
```

## Proste analizy i wizualizacje wyników

```{r}
lista_freq <- count(strajk_clean2, word, sort = T)

lista_freq_20 <- lista_freq %>%
  mutate(word = reorder(word, n)) %>%
  top_n(20, n)

ggplot(lista_freq_20) +
  geom_col(aes(n, word), fill = "#999999") +
  theme_minimal() +
  labs(x = "Liczba wystąpień", y = NULL) +
  theme(axis.text.x = element_text(hjust = 1, size = 13),
        axis.text.y = element_text(size = 14), 
        axis.title.x = element_text(size=14, face="bold", vjust=0.2))
```

```{r}
wordcloud(
  word = lista_freq$word, 
  freq = lista_freq$n, 
  max.words = 100, 
  colors = brewer.pal(7, "Dark2"), 
  scale = c(3.5,0.5),
  random.order = FALSE,
  rot.per=0.35
)
```
O co chodzi z "pętel" i "r"?

```{r}
kwic(strajk_lem$lemat, pattern = "r", window = 2, 
     valuetype = "fixed")

kwic(strajk_lem$lemat, pattern = "pętel", window = 2, 
     valuetype = "fixed")
```

Poprawiamy. 

```{r}
strajk_clean2$word <- gsub("pętel","pętla", strajk_clean2$word)

lista_freq <- strajk_clean2 %>%
  filter(!(word=="r")) %>%
  count(word, sort = T)

wordcloud(
  word = lista_freq$word, 
  freq = lista_freq$n, 
  max.words = 100, 
  colors = brewer.pal(7, "Dark2"), 
  scale = c(3.5,0.5),
  random.order = FALSE,
  rot.per=0.35
)
```

## Analiza wydźwięku

```{r}
slownik_sent <- read_xlsx("slownik_sent.xlsx")
```

```{r}
strajk_sent <- strajk_clean2 %>%
  inner_join(slownik_sent)

strajk_sent
```

```{r}
strajk_sent_2 <- strajk_sent %>%
  count(word, sent_1, sort = T)

strajk_sent_2
```

Zobaczmy najczęściej występujące słowa negatywne.

```{r}
strajk_sent_2 %>%
  filter(sent_1 < 0)
```

```{r}
strajk_sent_2 %>%
  filter(sent_1 > 0)
```

```{r}
strajk_sent_plot <- strajk_sent %>%
  mutate(date = as.Date(created_at, format="%Y-%m-%d %x"),
         sentyment = as.factor(sent_1)) %>%
  count(date, sentyment)

ggplot(strajk_sent_plot) +
  geom_line(aes(date, n, color = sentyment)) +
  theme_minimal() +
  ylab("Liczba słów")+
      xlab("")+
      theme(aspect.ratio=1/4)
```

```{r}
strajk_3 <- strajk_clean2 %>%
  mutate(date = as.Date(created_at, format="%Y-%m-%d %x")) %>%
  group_by(date) %>%
  mutate(words = n()) %>%
  ungroup()

strajk_plot2 <- strajk_3 %>%
  inner_join(slownik_sent) %>%
  count(date, sent_1, words) %>%
  group_by(date) %>%
  mutate(value = 100*(n/words)) %>%
  ungroup() %>%
  mutate(sentiment = as.factor(sent_1))

ggplot(strajk_plot2) +
  geom_line(aes(date, value, color = sentiment)) +
  theme_minimal() +
  ylab("%") +
  xlab("")+
  theme(aspect.ratio=1/4)
```



